{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a Decision Optimization model with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a Decision Optimization model, create and monitor jobs, and get solutions using the Watson Machine Learning Python Client.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Display the solution](#display)\n",
    "8. [Solve another problem using the same deployment](#problem)\n",
    "9. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client\n",
    "\n",
    "Before you use the sample code in this notebook, you need to:\n",
    "\n",
    "- create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-setup.html.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library. This notebook uses the preview Python client based on v4 of Watson Machine Learning APIs. \n",
    "\n",
    "**Important** Do not load both Python client libraries into a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall the Watson Machine Learning client Python client based on v3 APIs\n",
    "\n",
    "!pip uninstall watson-machine-learning-client -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the WML client API\n",
    "\n",
    "!pip install watson-machine-learning-client-V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance\n",
    "\n",
    "Use your Watson Machine Learning credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "wml_credentials = {\n",
    "      \"apikey\": \"XXXXXXXXXXX\",\n",
    "      \"instance_id\": \"XXXXXXXXXXXXX\",\n",
    "      \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Put the model.py file in a subdirectory and create a tar.gz file. The model consists of two parts:\n",
    "* some functions to create an `inputs` dictionary from files and create files from an `outputs` dictionary,\n",
    "* the real optimization model which uses the inputs and outputs dictionaries.\n",
    "\n",
    "Use the `write_file` command to write these models to a `main.py` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/main.py\n",
    "\n",
    "from docplex.util.environment import get_environment\n",
    "from os.path import splitext\n",
    "import pandas\n",
    "from six import iteritems\n",
    "\n",
    "def get_all_inputs():\n",
    "    '''Utility method to read a list of files and return a tuple with all\n",
    "    read data frames.\n",
    "    Returns:\n",
    "        a map { datasetname: data frame }\n",
    "    '''\n",
    "    result = {}\n",
    "    env = get_environment()\n",
    "    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\n",
    "        with env.get_input_stream(iname) as in_stream:\n",
    "            df = pandas.read_csv(in_stream)\n",
    "            datasetname, _ = splitext(iname)\n",
    "            result[datasetname] = df\n",
    "    return result\n",
    "\n",
    "def write_all_outputs(outputs):\n",
    "    '''Write all dataframes in ``outputs`` as .csv.\n",
    "\n",
    "    Args:\n",
    "        outputs: The map of outputs 'outputname' -> 'output df'\n",
    "    '''\n",
    "    for (name, df) in iteritems(outputs):\n",
    "        csv_file = '%s.csv' % name\n",
    "        print(csv_file)\n",
    "        with get_environment().get_output_stream(csv_file) as fp:\n",
    "            if sys.version_info[0] < 3:\n",
    "                fp.write(df.to_csv(index=False, encoding='utf8'))\n",
    "            else:\n",
    "                fp.write(df.to_csv(index=False).encode(encoding='utf8'))\n",
    "    if len(outputs) == 0:\n",
    "        print(\"Warning: no outputs written\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model/main.py\n",
    "\n",
    "# Load CSV files into inputs dictionnary\n",
    "inputs = get_all_inputs()\n",
    "\n",
    "food = inputs['diet_food']\n",
    "nutrients = inputs['diet_nutrients']\n",
    "food_nutrients = inputs['diet_food_nutrients']\n",
    "food_nutrients.set_index('Food', inplace=True)\n",
    "        \n",
    "from docplex.mp.model import Model\n",
    "\n",
    "# Model\n",
    "mdl = Model(name='diet')\n",
    "\n",
    "# Create decision variables, limited to be >= Food.qmin and <= Food.qmax\n",
    "qty = food[['name', 'qmin', 'qmax']].copy()\n",
    "qty['var'] = qty.apply(lambda x: mdl.continuous_var(lb=x['qmin'],\n",
    "                                                ub=x['qmax'],\n",
    "                                                name=x['name']),\n",
    "                   axis=1)\n",
    "# make the name the index\n",
    "qty.set_index('name', inplace=True)\n",
    "\n",
    "# Limit range of nutrients, and mark them as KPIs\n",
    "for n in nutrients.itertuples():\n",
    "    amount = mdl.sum(qty.loc[f.name]['var'] * food_nutrients.loc[f.name][n.name]\n",
    "                     for f in food.itertuples())\n",
    "    mdl.add_range(n.qmin, amount, n.qmax)\n",
    "    mdl.add_kpi(amount, publish_name='Total %s' % n.name)\n",
    "\n",
    "# Minimize cost\n",
    "obj = mdl.sum(qty.loc[f.name]['var'] * f.unit_cost for f in food.itertuples())\n",
    "mdl.add_kpi(obj, publish_name=\"Minimal cost\");\n",
    "mdl.minimize(obj)\n",
    "\n",
    "mdl.print_information()\n",
    "\n",
    "# solve\n",
    "ok = mdl.solve()\n",
    "\n",
    "mdl.print_solution()\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "solution_df = pandas.DataFrame(columns=['Food', 'value'])\n",
    "\n",
    "for index, dvar in enumerate(mdl.solution.iter_variables()):\n",
    "    solution_df.loc[index,'Food'] = dvar.to_string()\n",
    "    solution_df.loc[index,'value'] = dvar.solution_value\n",
    "    \n",
    "outputs = {}\n",
    "outputs['solution'] = solution_df\n",
    "        \n",
    "# Generate output files\n",
    "write_all_outputs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"model/main.py\", arcname=\"main.py\", filter=reset)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "META_PROP NAME            TYPE  REQUIRED  SCHEMA\n",
      "NAME                      str   Y\n",
      "DESCRIPTION               str   N\n",
      "INPUT_DATA_SCHEMA         dict  N         {'fields(required)': [{'nullable(optional)': 'string', 'name(required)': 'string', 'type(required)': 'string'}], 'id(required)': 'string'}\n",
      "TRAINING_DATA_REFERENCES  list  N         [{'connection(required)': {'access_key_id(required)': 'string', 'endpoint_url(required)': 'string', 'secret_access_key(required)': 'string'}, 'name(optional)': 'string', 'location(required)': {'path': 'string', 'bucket': 'string'}, 'schema(optional)': {'fields(required)': [{'nullable(optional)': 'string', 'name(required)': 'string', 'type(required)': 'string'}], 'id(required)': 'string'}, 'type(required)': 'string'}]\n",
      "OUTPUT_DATA_SCHEMA        dict  N         {'fields(required)': [{'nullable(optional)': 'string', 'name(required)': 'string', 'type(required)': 'string'}], 'id(required)': 'string'}\n",
      "LABEL_FIELD               str   N\n",
      "TRANSFORMED_LABEL_FIELD   str   N\n",
      "RUNTIME_UID               str   N\n",
      "TAGS                      list  N         [{'value(required)': 'string', 'description(optional)': 'string'}]\n",
      "SIZE                      dict  N         {'in_memory(optional)': 'string', 'content(optional)': 'string'}\n",
      "SPACE_UID                 str   N\n",
      "PIPELINE_UID              str   N\n",
      "RUNTIME_UID               str   Y\n",
      "TYPE                      str   Y\n",
      "CUSTOM                    dict  N\n",
      "DOMAIN                    str   N\n",
      "HYPER_PARAMETERS          dict  N\n",
      "METRICS                   list  N\n",
      "IMPORT                    dict  N         {'connection(required)': {'access_key_id(required)': 'string', 'endpoint_url(required)': 'string', 'secret_access_key(required)': 'string'}, 'name(optional)': 'string', 'location(required)': {'path': 'string', 'bucket': 'string'}, 'type(required)': 'string'}\n",
      "TRAINING_LIB_UID          str   N\n",
      "------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# All available meta data properties \n",
    "\n",
    "client.repository.ModelMetaNames.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------  --------------------------  ------------------------  --------\n",
      "GUID                        NAME                        CREATED                   PLATFORM\n",
      "xgboost_0.82-py3            xgboost_0.82-py3            2019-05-31T11:52:29.467Z  python\n",
      "scikit-learn_0.20-py3       scikit-learn_0.20-py3       2019-05-31T11:52:25.504Z  python\n",
      "pmml_4.3                    pmml_4.3                    2019-04-15T09:29:02.701Z  pmml\n",
      "pmml_4.2                    pmml_4.2                    2019-04-15T09:29:00.178Z  pmml\n",
      "pmml_4.1                    pmml_4.1                    2019-04-15T09:28:58.142Z  pmml\n",
      "pmml_4.0                    pmml_4.0                    2019-04-15T09:28:56.118Z  pmml\n",
      "pmml_3.2                    pmml_3.2                    2019-04-15T09:28:54.079Z  pmml\n",
      "pmml_3.1                    pmml_3.1                    2019-04-15T09:28:52.023Z  pmml\n",
      "pmml_3.0                    pmml_3.0                    2019-04-15T09:28:49.990Z  pmml\n",
      "do_12.9                     do_12.9                     2019-04-04T10:20:03.453Z  do\n",
      "pmml_4.2.1                  pmml_4.2.1                  2019-04-04T10:20:01.095Z  pmml\n",
      "ai-function_0.1-py3         ai-function_0.1-py3         2019-04-04T10:19:58.723Z  python\n",
      "hybrid_0.2                  hybrid_0.2                  2019-04-04T10:19:56.395Z  hybrid\n",
      "hybrid_0.1                  hybrid_0.1                  2019-04-04T10:19:54.084Z  hybrid\n",
      "xgboost_0.80-py3            xgboost_0.80-py3            2019-04-04T10:19:51.762Z  python\n",
      "xgboost_0.6-py3             xgboost_0.6-py3             2019-04-04T10:19:49.126Z  python\n",
      "spss-modeler_18.1           spss-modeler_18.1           2019-04-04T10:19:46.776Z  spss\n",
      "spss-modeler_17.1           spss-modeler_17.1           2019-04-04T10:19:44.466Z  spss\n",
      "scikit-learn_0.19-py3       scikit-learn_0.19-py3       2019-04-04T10:19:42.124Z  python\n",
      "scikit-learn_0.17-py3       scikit-learn_0.17-py3       2019-04-04T10:19:39.834Z  python\n",
      "spark-mllib_2.3             spark-mllib_2.3             2019-04-04T10:19:37.487Z  spark\n",
      "spark-mllib_2.2             spark-mllib_2.2             2019-04-04T10:19:35.193Z  spark\n",
      "spark-mllib_2.1             spark-mllib_2.1             2019-04-04T10:19:32.869Z  spark\n",
      "tensorflow_1.13-py3         tensorflow_1.13-py3         2019-04-04T10:19:30.526Z  python\n",
      "tensorflow_1.13-py2         tensorflow_1.13-py2         2019-04-04T10:19:28.199Z  python\n",
      "tensorflow_0.11-horovod     tensorflow_0.11-horovod     2019-04-04T10:19:25.880Z  native\n",
      "tensorflow_1.11-py3         tensorflow_1.11-py3         2019-04-04T10:19:23.581Z  python\n",
      "tensorflow_1.10-py3         tensorflow_1.10-py3         2019-04-04T10:19:21.246Z  python\n",
      "tensorflow_1.10-py2         tensorflow_1.10-py2         2019-04-04T10:19:18.910Z  python\n",
      "tensorflow_1.9-py3          tensorflow_1.9-py3          2019-04-04T10:19:16.600Z  python\n",
      "tensorflow_1.9-py2          tensorflow_1.9-py2          2019-04-04T10:19:14.259Z  python\n",
      "tensorflow_1.8-py3          tensorflow_1.8-py3          2019-04-04T10:19:11.939Z  python\n",
      "tensorflow_1.8-py2          tensorflow_1.8-py2          2019-04-04T10:19:09.589Z  python\n",
      "tensorflow_1.7-py3          tensorflow_1.7-py3          2019-04-04T10:19:07.191Z  python\n",
      "tensorflow_1.7-py2          tensorflow_1.7-py2          2019-04-04T10:19:04.901Z  python\n",
      "tensorflow_1.6-py3          tensorflow_1.6-py3          2019-04-04T10:19:02.546Z  python\n",
      "tensorflow_1.6-py2          tensorflow_1.6-py2          2019-04-04T10:19:00.217Z  python\n",
      "tensorflow_1.5-py2-ddl      tensorflow_1.5-py2-ddl      2019-04-04T10:18:57.905Z  python\n",
      "tensorflow_1.5-py3-horovod  tensorflow_1.5-py3-horovod  2019-04-04T10:18:55.520Z  python\n",
      "tensorflow_1.5-py3          tensorflow_1.5-py3          2019-04-04T10:18:53.195Z  python\n",
      "tensorflow_1.5-py2          tensorflow_1.5-py2          2019-04-04T10:18:50.876Z  python\n",
      "tensorflow_1.4-py2-ddl      tensorflow_1.4-py2-ddl      2019-04-04T10:18:48.543Z  python\n",
      "tensorflow_1.4-py3-horovod  tensorflow_1.4-py3-horovod  2019-04-04T10:18:46.217Z  python\n",
      "tensorflow_1.4-py3          tensorflow_1.4-py3          2019-04-04T10:18:43.898Z  python\n",
      "tensorflow_1.4-py2          tensorflow_1.4-py2          2019-04-04T10:18:41.584Z  python\n",
      "tensorflow_1.3-py2-ddl      tensorflow_1.3-py2-ddl      2019-04-04T10:18:39.271Z  python\n",
      "tensorflow_1.3-py3          tensorflow_1.3-py3          2019-04-04T10:18:36.905Z  python\n",
      "tensorflow_1.3-py2          tensorflow_1.3-py2          2019-04-04T10:18:34.556Z  python\n",
      "tensorflow_1.2-py3          tensorflow_1.2-py3          2019-04-04T10:18:32.250Z  python\n",
      "tensorflow_1.2-py2          tensorflow_1.2-py2          2019-04-04T10:18:29.956Z  python\n",
      "--------------------------  --------------------------  ------------------------  --------\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "# All available runtimes\n",
    "\n",
    "client.runtimes.list(pre_defined=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0ca0c313-93e6-40cd-ad6a-4160996c8ad1\n"
     ]
    }
   ],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"Diet\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Diet\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_12.9\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: \"do_12.9\"    \n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/dsxuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "\n",
    "model_uid = client.repository.get_model_uid(model_details)\n",
    "\n",
    "print( model_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '0ca0c313-93e6-40cd-ad6a-4160996c8ad1' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "ready\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='14b23f77-9542-4127-9730-6048201cd30f'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "14b23f77-9542-4127-9730-6048201cd30f\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Diet Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Diet Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.COMPUTE: {'name': 'S', 'nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------  -----  ------------------------  -------------\n",
      "GUID                                  NAME             STATE  CREATED                   ARTIFACT_TYPE\n",
      "14b23f77-9542-4127-9730-6048201cd30f  Diet Deployment  ready  2019-06-18T15:25:01+0000  model\n",
      "------------------------------------  ---------------  -----  ------------------------  -------------\n"
     ]
    }
   ],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library \n",
    "import pandas as pd \n",
    "  \n",
    "# initialize list of lists \n",
    "diet_food = pd.DataFrame([ [\"Roasted Chicken\", 0.84, 0, 10],\n",
    "                [\"Spaghetti W/ Sauce\", 0.78, 0, 10],\n",
    "                [\"Tomato,Red,Ripe,Raw\", 0.27, 0, 10],\n",
    "                [\"Apple,Raw,W/Skin\", 0.24, 0, 10],\n",
    "                [\"Grapes\", 0.32, 0, 10],\n",
    "                [\"Chocolate Chip Cookies\", 0.03, 0, 10],\n",
    "                [\"Lowfat Milk\", 0.23, 0, 10],\n",
    "                [\"Raisin Brn\", 0.34, 0, 10],\n",
    "                [\"Hotdog\", 0.31, 0, 10]] , columns = [\"name\",\"unit_cost\",\"qmin\",\"qmax\"])\n",
    "\n",
    "diet_food_nutrients = pd.DataFrame([\n",
    "                [\"Spaghetti W/ Sauce\", 358.2, 80.2, 2.3, 3055.2, 11.6, 58.3, 8.2],\n",
    "                [\"Roasted Chicken\", 277.4, 21.9, 1.8, 77.4, 0, 0, 42.2],\n",
    "                [\"Tomato,Red,Ripe,Raw\", 25.8, 6.2, 0.6, 766.3, 1.4, 5.7, 1],\n",
    "                [\"Apple,Raw,W/Skin\", 81.4, 9.7, 0.2, 73.1, 3.7, 21, 0.3],\n",
    "                [\"Grapes\", 15.1, 3.4, 0.1, 24, 0.2, 4.1, 0.2],\n",
    "                [\"Chocolate Chip Cookies\", 78.1, 6.2, 0.4, 101.8, 0, 9.3, 0.9],\n",
    "                [\"Lowfat Milk\", 121.2, 296.7, 0.1, 500.2, 0, 11.7, 8.1],\n",
    "                [\"Raisin Brn\", 115.1, 12.9, 16.8, 1250.2, 4, 27.9, 4],\n",
    "                [\"Hotdog\", 242.1, 23.5, 2.3, 0, 0, 18, 10.4 ]\n",
    "            ] , columns = [\"Food\",\"Calories\",\"Calcium\",\"Iron\",\"Vit_A\",\"Dietary_Fiber\",\"Carbohydrates\",\"Protein\"])\n",
    "\n",
    "diet_nutrients = pd.DataFrame([\n",
    "                [\"Calories\", 2000, 2500],\n",
    "                [\"Calcium\", 800, 1600],\n",
    "                [\"Iron\", 10, 30],\n",
    "                [\"Vit_A\", 5000, 50000],\n",
    "                [\"Dietary_Fiber\", 25, 100],\n",
    "                [\"Carbohydrates\", 0, 300],\n",
    "                [\"Protein\", 50, 100]\n",
    "            ], columns = [\"name\",\"qmin\",\"qmax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d926354-b0fa-44eb-9444-d93027483d3c\n"
     ]
    }
   ],
   "source": [
    "solve_payload = {\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"diet_food.csv\",\n",
    "            \"values\" : diet_food\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_food_nutrients.csv\",\n",
    "            \"values\" : diet_food_nutrients\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_nutrients.csv\",\n",
    "            \"values\" : diet_nutrients\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.csv\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)\n",
    "\n",
    "print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "running...\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print( job_details['entity']['decision_optimization']['status']['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='display'></a>\n",
    "### Extract and display solution\n",
    "\n",
    "Display the output solution.\n",
    "\n",
    "Display the KPI Total Calories value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spaghetti W/ Sauce</td>\n",
       "      <td>2.155172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chocolate Chip Cookies</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lowfat Milk</td>\n",
       "      <td>1.831167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotdog</td>\n",
       "      <td>0.929698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Food      value\n",
       "0      Spaghetti W/ Sauce   2.155172\n",
       "1  Chocolate Chip Cookies  10.000000\n",
       "2             Lowfat Milk   1.831167\n",
       "3                  Hotdog   0.929698"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe for the solution\n",
    "solution = pd.DataFrame(job_details['entity']['decision_optimization']['output_data'][0]['values'], \n",
    "                        columns = job_details['entity']['decision_optimization']['output_data'][0]['fields'])\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000.0000000000002\n"
     ]
    }
   ],
   "source": [
    "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='problem'></a>\n",
    "###  Solve another problem using the same deployment\n",
    "\n",
    "Create a new payload with modified input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the input data\n",
    "diet_nutrients.at[0,'qmin'] = 1500\n",
    "diet_nutrients.at[0,'qmax'] = 2000\n",
    "\n",
    "solve_payload = {\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"diet_food.csv\",\n",
    "            \"values\" : diet_food         \n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_food_nutrients.csv\",\n",
    "             \"values\" : diet_food_nutrients            \n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_nutrients.csv\",\n",
    "            \"values\" : diet_nutrients\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.csv\"\n",
    "    }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85f4637d-2d82-417b-b6ae-0eb2c276c2f0\n"
     ]
    }
   ],
   "source": [
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)\n",
    "\n",
    "print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued...\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print( job_details['entity']['decision_optimization']['status']['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the KPI Total Calories value for this modified data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499.9999999999998\n"
     ]
    }
   ],
   "source": [
    "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completed_at': '2019-06-18T15:27:02.848Z', 'state': 'completed', 'running_at': '2019-06-18T15:27:01.782Z'}\n"
     ]
    }
   ],
   "source": [
    "print(client.deployments.get_job_details(job_uid)['entity']['decision_optimization']['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "- display the solution\n",
    "\n",
    "Check out our online documentation at <a href=\"https://dataplatform.cloud.ibm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">https://dataplatform.cloud.ibm.com/docs</a> for more samples, tutorials and documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
